library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
adData = data.frame(predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
adData = data.frame(predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
cut2()
library(Hmisc)
str(training)
str(concrete)
plot(Concrete$CompressiveStrength)
plot(concrete$CompressiveStrength)
xyplot(concrete$CompressiveStrength)
qplot(concrete$CompressiveStrength)
plot(concrete$CompressiveStrength)
plot(concrete$CompressiveStrength,col=Cement)
with(cement) plot(CompressiveStrength,col=Cement)
with(cement) {plot(CompressiveStrength,col=Cement){}
with(cement) {plot(CompressiveStrength,col=Cement)
with(cement) {plot(CompressiveStrength,col=Cement)}
with(cement, plot(CompressiveStrength,col=Cement))
with(concrete, plot(CompressiveStrength,col=Cement))
qplot(seq_along(CompressiveStrength),CompressiveStrength,data=concrete)
qplot(seq_along(CompressiveStrength),CompressiveStrength,data=concrete,col=c(Cement,BlastFurnaceSlag))
qplot(seq_along(CompressiveStrength),CompressiveStrength,data=concrete,col=aes(Cement,BlastFurnaceSlag))
qplot(seq_along(CompressiveStrength),CompressiveStrength,data=concrete,col=Cement)
str(cement)
str(concrete)
qplot(seq_along(CompressiveStrength),CompressiveStrength,data=concrete,col=Age)
qplot(seq_along(CompressiveStrength),CompressiveStrength,data=concrete,col=FlyAsh)
cut2()
cut2(FlyAsh)
cut2(concrete$FlyAsh)
cut2(concrete$FlyAsh)$Levels
cut2(concrete$FlyAsh).levels
cut2(concrete$FlyAsh)
qplot(seq_along(CompressiveStrength),CompressiveStrength,data=concrete,col=cut2(concrete$FlyAsh))
qplot(seq_along(CompressiveStrength),CompressiveStrength,data=concrete,col=Age)
qplot(seq_along(CompressiveStrength),CompressiveStrength,data=concrete,col=cut2(concrete$Age))
qplot(seq_along(CompressiveStrength),CompressiveStrength,data=training,col=cut2(trainig$Age))
qplot(seq_along(CompressiveStrength),CompressiveStrength,data=training,col=cut2(training$Age))
qplot(seq_along(CompressiveStrength),CompressiveStrength,data=training,col=cut2(training$FlyAsh))
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
qplot(SuperPlasticizer,data=training
)
str(training)
qplot(Superplasticizer,data=training)
qplot(log(Superplasticizer),data=training)
summary(training)
log(0)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
str(training)
str(training['IL'])
str(training[,"IL"])
str(training$IL
)
training$IL
training[I]
training[IL]
training['IL']
training[,'IL']
training[,"IL"]
training[,c('IL')]
training[,c("IL")]
training[,c("IL_9")]
str(training$IL
training[,"IL"]
str(training)
matchcols(training, with=c("IL"),
method="or"
)
?matchcol
?matchcols
??matchcols
training[,"IL",exact=FALSE]
training["IL",exact=FALSE]
training$IL
training$IL[,]
training
str(training)
training["IL_3"]
training["IL_",exact=FALSE]
training[["IL_",exact=FALSE]]
names(training)
training$IL_3
training$IL
str(training)
training[,grep("$IL",as.character(names(training)))]
grep("$IL",as.character(names(training)))
grep("$IL",names(training))
grep("IL",names(training))
grep("^IL",names(training))
training[,grep("^IL",names(training))]
tr<-training[,grep("^IL",names(training))]
pr<-preProces(tr,method="pca")
library(caret)
pr<-preProces(tr,method="pca")
pr<-preProcess(tr,method="pca")
pr
names(prcomp(pr)
)
names(prcomp(pr))
pr<-preProcess(tr,pcaComp,k=2)
pr<-preProcess(tr,pcaComp=2)
pr
pr$finalModel
print(pr)
str(pr)
pr<-preProcess(tr,method="pca",tresh=0.8)
pr$rotation
pr<-preProcess(tr,method="pca",tresh=0.95)
pr$rotation
pr<-preProcess(tr,method="pca",tresh=0.4)
pr$rotation
pr<-preProcess(tr,method="pca",tresh=0.1)
pr$rotation
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
train2 <- training[,grep("^IL",names(training))]
train2 <- data.frame(training$diagnosis,train2)
modelFit<- train(diagnosis~.,data=train2,method="gbm")
str(train2)
modelFit<- train(training.diagnosis~.,data=train2,method="gbm")
pred <- prediction(modelFit,testing)
pred <- predict(modelFit,testing)
confusionMatrix(pred,testing)
confusionMatrix(pred,testing$disgnosis)
str(pred)
confusionMatrix(pred,testing$diagnosis)
train3 <- preProcess(train2,method="pca",tresh=0.8)
train3 <- preProcess(train2[2:ncol(train2)],method="pca",tresh=0.8)
train3
modelFit<- train(training.diagnosis~.,data=train3,method="gbm")
preProc <- preProcess(train2[2:ncol(train2)],method="pca",tresh=0.8)
trainPC <- predict(preProc,train2)
trainPC <- predict(preProc,train2[2:ncol(train2)])
str(trainPC)
tainPC<-dataframe(diagnosis=train2.diagnosis,trainPC)
tainPC<-data.frame(diagnosis=train2.diagnosis,trainPC)
tainPC<-data.frame(diagnosis=train2$diagnosis,trainPC)
tainPC<-data.frame(diagnosis=train2$training.diagnosis,trainPC)
str(trainPC)
str(train2)
tainPC<-data.frame(train2$training.diagnosis,trainPC)
str(trainPC)
train2$training.diagnosis
str(data.frame(train2$training.diagnosis,trainPC))
trainPC2<-data.frame(train2$training.diagnosis,trainPC)
str(trainPC2)
names(trainPC2)
names(trainPC2) <- c("diagnosis",names(trainsPC2)[2:11])
names(trainPC2) <- c("diagnosis",names(trainPC2)[2:11])
str(trainPC2)
modelFitPCA<-train(diagnosis~.,data=trainPC2,method="glm")
predPCA<-predict(modelFitPCA,testing)
predPCA<-predict(modelFitPCA,predict(preProc,testing)
)
testPCA<-predict(preProc,testing)
testPCA<-predict(preProc,testing[2:ncol(testing)])
str(testing)
testPCA<-predict(preProc,testing[grep("^IL",testing)])
testPCA<-predict(preProc,testing[,grep("^IL",testing)])
test2<-testing[,grep("^IL",testing)]
testPCA<-predict(preProc,test2[,grep("^IL",test2)])
testPCA<-predict(preProc,testing[,grep("^IL",names(testing))])
predPCA<-predict(modelFitPCA,testPCA)
confusionMatrix(predPCA,testing)
predPCA
confusionMatrix(predPCA,testing$diagnosis)
confusionMatrix(pred,testing$diagnosis)
modelFit<- train(training.diagnosis~.,data=train2,method="glm")
pred <- predict(modelFit,testing)
confusionMatrix(pred,testing$diagnosis)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
train<-training[,grep("^IL",names(training))]
str(train)
preProc<-preProcess(train,method="pca",tresh=0.8)
preProc$rotation
preProc
preProc<-preProcess(train,method="pca",pcaComp=7)
preProc
preProc$dev
preProc$sdev
preProc$rotation
preProc<-preProcess(train,method="pca")
preProc
preProc<-preProcess(train,method="pca",tresh=0.8)
preProc$std
preProc$numComp
preProc
summary(preProc)
summary(preProc.pca)
prePCA <-prcomp(train)
summary(prePCA)
str(train)
prePCA <-prcomp(train,center = TRUE,
scale. = TRUE)
summary(prePCA)
preProc <- preProcess(train,method=c("center","scale","pca"),tresh=0.8)
preProc
summary(preProc)
preProc$rotation
preProc <- preProcess(train,method=c("center","scale","pca"),thresh=0.8)
preProc
preProc <- preProcess(train,method=c("center","scale","pca"),thresh=0.9)
prePRoc
prerRoc
preProc
pnorm(70,mean=80,sd=10)
qnorm(0.95,mean=1100,sd=75)
1100 + c(-1,1)*qnorm(0.95)*75/sqrt(100)
pbinom(4,size=5,prob=0.5)
qbinom(4,size=5,prob=0.5)
pbinom(4,size=5,prob=0.5,lower.tail=false)
pbinom(4,size=5,prob=0.5,lower.tail=FALSE)
0.5*0.5*0.5*0,5
0.5*0.5*0.5*0.5
pbinom(3,size=5,prob=0.5,lower.tail=FALSE)
choose(5,4)*0.5^5+choose(5,5)*0.5^5
binom.test(15,10)
binom.test(15,100)$conf.int
15+c(1,1)*qnorm(0.95)*sqrt(15*10/100)
15+c(-1,1)*qnorm(0.95)*sqrt(15*10/100)
15+c(-1,1)*qnorm(0.68)*sqrt(15*10/100)
15+c(-1,1)*qnorm(0.47)*sqrt(15*10/100)
poisson.test(5,3)
ppois(10,lambda=5*3)
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
fit<-lm(y~x)
summary(fit)$coefficients
summary(fit)$sigma
data(mtcars)
mtcars
str(mtcars)
fit<-lm(mpg~wt)
with(mtcars,fit<-lm(mpg~wt))
fit
y<-predict(fit,mean(mtcars(wt)))
y<-predict(fit,mean(mtcars$wt)))
y<-predict(fit,mean(mtcars$wt))
y
mean(mtcars$wt)
y<-predict(fit,wt=mean(mtcars$wt))
y
coef(fit)
y<-coef(fit)[1]+coef(fit)[2]*mean(mtcars$wt)
y
coef(fit)[2]
coef(fit)[1]
coef(fit)[1,1]
coef(fit)[1]
y
newdata <- data.frame(wt = mean(mtcars$wt))
newdata
p2<-predict(fit,newdata,interval=("prediction"))
p2
fit
p2<-predict(fit,newdata,interval=("prediction"))
p2
p2<-predict(fit,data=newdata,interval=("prediction"))
p2
p2<-predict(fit,data=newdata
)
p2
newdata
p2<-predict(fit,data=mtacars,interval=("prediction"))
p2<-predict(fit,newdata$wt,interval=("prediction"))
p2
p2<-predict(fit,mtcars$wt,interval=("prediction"))
p2
p2<-predict(fit,mtcars$wt)
with(mtcars,fit<-lm(mpg~wt))
summary(fit)
y<-coef(fit)[1]+coef(fit)[2]*mean(mtcars$wt)
y
sigma
beta0<-coef(fit)[1]
beta1<-coef(fit[2])
beta1<-coef(fit)[2]
beta0
beta1
e<-mtcars$mpg-beta0-beta1*x
e
sigma<-sqrt(sum(e^2)/(length(mtcars$mpg)-2))
sigma
e<-mtcars$mpg-beta0-beta1*mtcars$wt
e
sigma<-sqrt(sum(e^2)/(length(mtcars$mpg)-2))
ssx<-sum((mtcars$wt-mean(mtcars$wt))^2)
se2<-sigma*sqrt(1+1/length(mtcars$mpg)+0)
se2
y<-coef(fit)[1]+coef(fit)[2]*mean(mtcars$wt)
y
y-se2
qt(0.95)
qt(0.95,df=lentgh(mtcars$mpg))
qt(0.95,df=length(mtcars$mpg))
y-c(-1,1)*qt(0.95,df=lentgh(mtcars$mpg))*se2
y-c(-1,1)*qt(0.95,df=length(mtcars$mpg))*se2
summary(fit)
summary(fit)$sigma
sigma<-summary(fit)$sigma
y-c(-1,1)*qt(0.95,df=lentgh(mtcars$mpg))*se2
y-c(-1,1)*qt(0.95,df=length(mtcars$mpg))*se2
se2<-sigma*sqrt(1+1/length(mtcars$mpg)+0)
y-c(-1,1)*qt(0.95,df=length(mtcars$mpg))*se2
summary(fit)$standardError
summary(fit)
summary(fit)$Std.Error
summary(fit)$std.Error
summary(fit)$stdErr
str(summary(fit))
summary(fit)$coefficients
summary(fit)$coefficients[2,2]
se2<-summary(fit)$coefficients[2,2]
y-c(-1,1)*qt(0.95,df=length(mtcars$mpg))*se2
y-c(-1,1)*qt(0.95,df=length(mtcars$mpg)-2)*se2
y-c(-1,1)*qt(0.95,df=2)*se2
y-c(-1,1)*pt(0.95,df=2)*se2
mtcars$wt
mean(mtcars$wt)
y<-coef(fit)[1]+coef(fit)[2]*mean(mtcars$wt)
y
y<-coef(fit)[2]*mean(mtcars$wt)
y
y<-coef(fit)[1]
y
mtcars$mpg
fit<-lm(mtcars$mpg~mtcars$wt)
fit
y-c(-1,1)*pt(0.95,df=2)*se2
se2<-summary(fit)$coefficients[2,2]
se2
y-c(-1,1)*pt(0.95,df=length(mtcars$mpg,2))*se2
y-c(-1,1)*pt(0.95,df=length(mtcars$mpg)-2)*se2
y
y<-predict(fit,mean(mtcars$wt))
y
y<-coef(fit)[2]*mean(mtcars$wt)
y
y<-coef(fit)[1]+coef(fit)[2]*mean(mtcars$wt)
y
y-c(-1,1)*pt(0.95,df=length(mtcars$mpg)-2)*se2
y-c(-1,1)*qt(0.95,df=length(mtcars$mpg)-2)*se2
se2
summary(fit)
se2
y-c(-1,1)*qt(0.95,df=2*se2
)
y-c(-1,1)*pt(0.95,df=2*se2
)
newdata
predict(fit,newdata$wt,interval=("prediction"))
help(mtcars)
newdata<-data.frame(wt=3)
predict(fit,newdata$wt,interval=("prediction"))
predict(fit,newdata$wt)
predict(fit,wt=newdata$wt,interval=("prediction"))
predict(fit,data=newdata,interval=("prediction"))
newdata
predict(fit,newdata,interval=("prediction"))
predict(fit,newdata,interval=("confidence"))
x=mtcars$wt
y=mtcars$mpg
fit<-lm(y~x)
avg=mean(x)
avg
newdata=data.frame(x=avg)
predict(fit,newdata)
predict(fit,newdata,interval=("confidence"))
newdata=data.frame(x=3)
predict(fit,newdata,interval=("confidence"))
predict(fit,newdata,interval=("prediction"))
newdata=data.frame(x=2)
predict(fit,newdata,interval=("prediction"))
predict(fit,newdata,interval=("confidence"))
coef(fit)
predict(fit,newdata,interval=("confidence"))-coef(fit)[1]
summary(fit)
-5.3445+c(-1,1)*pt(0.95,df=fit$df)*summary(fit)$coefficients[2,1]
summary(fit)$coefficients[2,1]
summary(fit)$coefficients[2,2]
-5.3445+c(-1,1)*pt(0.95,df=fit$df)*summary(fit)$coefficients[2,2]
-5.3445+c(-1,1)*qt(0.95,df=fit$df)*summary(fit)$coefficients[2,2]
-5.3445*2+c(-1,1)*qt(0.95,df=fit$df)*summary(fit)$coefficients[2,2]
-5.3445/2+c(-1,1)*qt(0.95,df=fit$df)*summary(fit)$coefficients[2,2]
-5.3445*2+c(-1,1)*qt(0.95,df=fit$df)*summary(fit)$coefficients[2,2]
-5.3445*2+c(-1,1)*2*qt(0.95,df=fit$df)*summary(fit)$coefficients[2,2]
fit1<-lm(y~x)
fit1<-lm(y~1)
fit1<-lm(y~x)
fit2<-lm(y~1)
fit1$residuals
sr1<-sum(fit1$residuals^2)
sr2<-sum(fit2$residuals^2)
sr1/sr2
sr2/sr1
sum(fit2$residuals)
data(mtcars)
str(mtcars)
install.packages("shiny")
install.packages('devtools')
devtools::install_github('rstudio/shinyapps')
install.packages("RTools")
install.packages("Rtools")
shinyapps::setAccountInfo(name='marozet', token='48F7BF42940148CE72A2E6ADE24F9080', secret='Ou14rEoLUJC/2hS4MDOmwvPW3z9E1zGi1Jp4XGux')
library(devtools)
install_github('slidify','ramnathv')
install_github('ramnathv/slidify')
install_github('ramnathv/slidifyLibraris')
install_github('ramnathv/slidifyLibraries')
library(slidify)
setwd("F:/GitHub/RepData_PeerAssessment1")
mydata<-read.csv("activity.zip")
nrow(mydata)
View(mydata)
download.file("https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2Factivity.zip","repdata_data_activity.zip",mode="wb")
download.file("http://d396qusza40orc.cloudfront.net/repdata%2Fdata%2Factivity.zip","repdata_data_activity.zip",mode="wb")
mydata<-read.csv("repdata_data_activity.zip")
nrow(mydata)
download.file("http://d396qusza40orc.cloudfront.net/repdata%2Fdata%2Factivity.zip","repdata_data_activity.zip",mode="wb")
mydata<-read.csv(unz("repdata_data_activity.zip","activity.csv")
nrow(mydata)
download.file("http://d396qusza40orc.cloudfront.net/repdata%2Fdata%2Factivity.zip","repdata_data_activity.zip",mode="wb")
mydata<-read.csv(unz("repdata_data_activity.zip","activity.csv"))
nrow(mydata)
View(mydata)
require(ddplyr)
require(dplyr)
suppressMessages(library(dplyr))
View(mydata)
stepsByDay <- mydata %>% group_by(date) %>% summarize(stepsByDay=sum(steps))
View(stepsByDay)
stepsByDay <- mydata %>% group_by(date) %>% summarize(stepsByDay=sum(steps,na.rm=TRUE))
View(stepsByDay)
stepsByInterval <- mydata %>% group_by(interval) %>% summarize(stepsMeanByInterval=mean(steps))
View(stepsByInterval)
mydataNAImputed <- mydata
impute.median <- function(x) replace(x, is.na(x), median(x, na.rm = TRUE)) #define function for imputing data
#perform imputing grouped by interval
mydataNAImputed <- ddply(mydataNAImputed, ~ interval, transform, steps = impute.median(steps))
library(plyr)
mydataNAImputed <- mydata
impute.median <- function(x) replace(x, is.na(x), median(x, na.rm = TRUE)) #define function for imputing data
#perform imputing grouped by interval
mydataNAImputed <- ddply(mydataNAImputed, ~ interval, transform, steps = impute.median(steps))
View(mydataNAImputed)
View(mydata)
mydataNAImputed <- mydata
impute.median <- function(x) replace(x, is.na(x), mean(x, na.rm = TRUE)) #define function for imputing data
#perform imputing grouped by interval
mydataNAImputed <- ddply(mydataNAImputed, ~ interval, transform, steps = impute.median(steps))
summary(mydataNAImputed)
View(mydataNAImputed)
mydataNAImputed <- mydata
impute.median <- function(x) replace(x, is.na(x), round(mean(x, na.rm = TRUE))) #define function for imputing data
#perform imputing grouped by interval
mydataNAImputed <- ddply(mydataNAImputed, ~ interval, transform, steps = impute.median(steps))
summary(mydataNAImputed)
View(mydataNAImputed)
find_rtools()
library(devtools)
find_rtools()
install.packages("KernSmooth")
library(KernSmooth)
